300 dim command
python main.py --exp_name egy-msa-lstm --transformer False  --emb_dim 300  --n_enc_layers 3 --n_dec_layers 3 --share_enc 3 --share_dec 3 --share_lang_emb True --share_output_emb True  --langs 'egy,msa' --n_mono -1 --mono_dataset 'egy:./data/arabic-egy-msa/mono/all.egy.tok.60000.pth,,;msa:./data/arabic-egy-msa/mono/all.msa.tok.60000.pth,,'  --para_dataset 'egy-msa:./data/arabic-egy-msa/para/dev/parallelsentences-4.XX-test.60000.pth,./data/arabic-egy-msa/para/dev/parallelsentences-4.XX-valid.60000.pth,./data/arabic-egy-msa/para/dev/parallelsentences-4.XX-test.60000.pth'  --mono_directions 'egy,msa' --word_shuffle 3 --word_dropout 0.1 --word_blank 0.2 --pivo_directions 'egy-msa-egy,msa-egy-msa'  --pretrained_emb './data/arabic-egy-msa/mono/all.egy-msa.60000.vec' --pretrained_out True --lambda_xe_mono '0:1,100000:0.1,300000:0' --lambda_xe_otfd 1  --otf_num_processes 10 --otf_sync_params_every 1000 --enc_optimizer adam,lr=0.0001   --stopping_criterion bleu_egy_msa_valid,10 --batch_size 16  --hidden_dim 300 --epoch_size 500000 --max_len=100  --share_encdec_emb True --share_decpro_emb True --share_output_emb True  --exp_id  test1

Transformer ----> test1
python main.py --exp_name test-egy-msa-transformer --transformer True  --emb_dim 300  --n_enc_layers 3 --n_dec_layers 3 --share_enc 3 --share_dec 3 --share_lang_emb True --share_output_emb True  --langs 'egy,msa' --n_mono -1 --mono_dataset 'egy:./data/arabic-egy-msa/mono/all.egy.tok.60000.pth,,;msa:./data/arabic-egy-msa/mono/all.msa.tok.60000.pth,,'  --para_dataset 'egy-msa:./data/arabic-egy-msa/para/dev/parallelsentences-5.XX-train.60000.pth,./data/arabic-egy-msa/para/dev/parallelsentences-5.XX-valid.60000.pth,./data/arabic-egy-msa/para/dev/parallelsentences-5.XX-test.60000.pth'  --mono_directions 'egy,msa' --word_shuffle 3 --word_dropout 0.1 --word_blank 0.2 --pivo_directions 'egy-msa-egy,msa-egy-msa'  --pretrained_emb './data/arabic-egy-msa/mono/all.egy-msa.60000.vec' --pretrained_out True --lambda_xe_mono '0:1,100000:0.1,300000:0' --lambda_xe_otfd 1  --otf_num_processes 10 --otf_sync_params_every 1000 --enc_optimizer adam,lr=0.0001   --stopping_criterion bleu_egy_msa_valid,10 --batch_size 16  --hidden_dim 300 --epoch_size 500000 --encoder_attention_heads 10 --decoder_attention_heads 10  --max_len=100  --share_encdec_emb True --share_decpro_emb True --share_output_emb True    --para_directions 'egy-msa,msa-egy' --n_para  -1   --lambda_xe_para '0:1,10000:0.1,30000:0'  --exp_id  test1

Transformer ----> test1 - 1   version 2
python main.py --exp_name test-egy-msa-transformer --transformer True  --emb_dim 300  --n_enc_layers 3 --n_dec_layers 3 --share_enc 3 --share_dec 3 --share_lang_emb True --share_output_emb True  --langs 'egy,msa' --n_mono -1 --mono_dataset 'egy:./data/arabic-egy-msa/mono/all.egy.tok.60000.pth,,;msa:./data/arabic-egy-msa/mono/all.msa.tok.60000.pth,,'  --para_dataset 'egy-msa:./data/arabic-egy-msa/para/dev/parallelsentences-5.XX-test.60000.pth,./data/arabic-egy-msa/para/dev/parallelsentences-5.XX-valid.60000.pth,./data/arabic-egy-msa/para/dev/parallelsentences-5.XX-test.60000.pth'  --mono_directions 'egy,msa' --word_shuffle 3 --word_dropout 0.1 --word_blank 0.2 --pivo_directions 'egy-msa-egy,msa-egy-msa'  --pretrained_emb './data/arabic-egy-msa/mono/all.egy-msa.60000.vec' --pretrained_out True --lambda_xe_mono '0:1,100000:0.1,300000:0' --lambda_xe_otfd 1  --otf_num_processes 10 --otf_sync_params_every 1000 --enc_optimizer adam,lr=0.0001   --stopping_criterion bleu_egy_msa_valid,10 --batch_size 16  --hidden_dim 300 --epoch_size 500000 --encoder_attention_heads 10 --decoder_attention_heads 10  --max_len=100  --share_encdec_emb True --share_decpro_emb True --share_output_emb True    --para_directions 'egy-msa,msa-egy' --n_para  -1   --lambda_xe_para '0:1,10000:0.1,30000:0'  --exp_id  test1

lstm ----> test2 without mono training
python main.py --exp_name test-egy-msa-lstm --transformer False  --emb_dim 300  --n_enc_layers 3 --n_dec_layers 3 --share_enc 3 --share_dec 3 --share_lang_emb True --share_output_emb True  --langs 'egy,msa' --n_mono -1 --mono_dataset 'egy:./data/arabic-egy-msa/mono/all.egy.tok.60000.pth,,;msa:./data/arabic-egy-msa/mono/all.msa.tok.60000.pth,,'  --para_dataset 'egy-msa:./data/arabic-egy-msa/para/dev/parallelsentences-7.XX-train.60000.pth,./data/arabic-egy-msa/para/dev/parallelsentences-6.XX-valid.60000.pth,./data/arabic-egy-msa/para/dev/parallelsentences-6.XX-test.60000.pth'  --mono_directions 'egy,msa' --word_shuffle 3 --word_dropout 0.1 --word_blank 0.1 --pivo_directions ''  --pretrained_emb './data/arabic-egy-msa/mono/all.egy-msa.60000.vec' --pretrained_out True --lambda_xe_mono '0:0,100000:0,300000:0' --lambda_xe_otfd 0  --otf_num_processes 10 --otf_sync_params_every 1000 --enc_optimizer adam,lr=0.0001   --stopping_criterion bleu_egy_msa_valid,10 --batch_size 10  --hidden_dim 300 --epoch_size 500000   --share_encdec_emb True --share_decpro_emb True --share_output_emb True    --para_directions 'egy-msa,msa-egy' --n_para  -1   --lambda_xe_para '0:0.7,10000:0.2,30000:0.001'  --exp_id  test2

Transformer ----> test2 without mono training
python main.py --exp_name test-egy-msa-lstm --transformer False  --emb_dim 300  --n_enc_layers 5 --n_dec_layers 5 --share_enc 3 --share_dec 3 --share_lang_emb True --share_output_emb True  --langs 'egy,msa' --n_mono -1 --mono_dataset 'egy:./data/arabic-egy-msa/mono/all.egy.tok.60000.pth,,;msa:./data/arabic-egy-msa/mono/all.msa.tok.60000.pth,,'  --para_dataset 'egy-msa:./data/arabic-egy-msa/para/dev/parallelsentences-6.XX-valid.60000.pth,./data/arabic-egy-msa/para/dev/parallelsentences-6.XX-train.60000.pth,./data/arabic-egy-msa/para/dev/parallelsentences-6.XX-valid.60000.pth'  --mono_directions 'egy,msa' --word_shuffle 3 --word_dropout 0.1 --word_blank 0.1 --pivo_directions ''  --pretrained_emb './data/arabic-egy-msa/mono/all.egy-msa.60000.vec' --pretrained_out True --lambda_xe_mono '0:0,100000:0,300000:0' --lambda_xe_otfd 0  --otf_num_processes 10 --otf_sync_params_every 1000 --enc_optimizer adam,lr=0.0001   --stopping_criterion bleu_egy_msa_valid,10 --batch_size 10  --hidden_dim 300 --epoch_size 500000   --share_encdec_emb True --share_decpro_emb True --share_output_emb True    --para_directions 'egy-msa' --n_para  -1   --lambda_xe_para '0:1,10000:0.2,30000:0.001'  --encoder_attention_heads 10 --decoder_attention_heads 10  --exp_id  test1


512 
python main.py --exp_name test-egy-msa-lstm --transformer False  --emb_dim 512  --n_enc_layers 3 --n_dec_layers 3 --share_enc 3 --share_dec 3 --share_lang_emb True --share_output_emb True  --langs 'egy,msa' --n_mono -1 --mono_dataset 'egy:./data/arabic-egy-msa/mono/all.egy.tok.60000.pth,,;msa:./data/arabic-egy-msa/mono/all.msa.tok.60000.pth,,'  --para_dataset 'egy-msa:./data/arabic-egy-msa/para/dev/parallelsentences-5.XX-valid.60000.pth,./data/arabic-egy-msa/para/dev/parallelsentences-5.XX-valid.60000.pth,./data/arabic-egy-msa/para/dev/parallelsentences-5.XX-test.60000.pth'  --mono_directions 'egy,msa' --word_shuffle 3 --word_dropout 0.1 --word_blank 0.1 --pivo_directions ''  --pretrained_emb './data/arabic-egy-msa/mono/all.egy-msa.60000.vec' --pretrained_out True --lambda_xe_mono '0:0,100000:0,300000:0' --lambda_xe_otfd 0  --otf_num_processes 20 --otf_sync_params_every 1000 --enc_optimizer adam,lr=0.0001   --stopping_criterion bleu_egy_msa_valid,100 --batch_size 16  --epoch_size 500000   --share_encdec_emb True --share_decpro_emb True --share_output_emb True    --para_directions 'egy-msa,msa-egy' --n_para  -1   --lambda_xe_para '0:0.7,10000:0.2,30000:0.001'


python main.py --exp_name test-egy-msa-transformer --transformer True  --emb_dim 512  --n_enc_layers 3 --n_dec_layers 3 --share_enc 3 --share_dec 3 --share_lang_emb True --share_output_emb True  --langs 'egy,msa' --n_mono -1 --mono_dataset 'egy:./data/arabic-egy-msa/mono/all.egy.tok.60000.pth,,;msa:./data/arabic-egy-msa/mono/all.msa.tok.60000.pth,,'  --para_dataset 'egy-msa:./data/arabic-egy-msa/para/dev/parallelsentences-5.XX-train.60000.pth,./data/arabic-egy-msa/para/dev/parallelsentences-5.XX-valid.60000.pth,./data/arabic-egy-msa/para/dev/parallelsentences-5.XX-test.60000.pth'  --mono_directions 'egy,msa' --word_shuffle 3 --word_dropout 0.1 --word_blank 0.2 --pivo_directions 'egy-msa-egy,msa-egy-msa'  --pretrained_emb './data/arabic-egy-msa/mono/all.egy-msa.60000.vec' --pretrained_out True --lambda_xe_mono '0:1,100000:0.1,300000:0' --lambda_xe_otfd 1  --otf_num_processes 10 --otf_sync_params_every 1000 --enc_optimizer adam,lr=0.0001   --stopping_criterion bleu_egy_msa_valid,10 --batch_size 16  --epoch_size 500000   --max_len=100  --share_encdec_emb True --share_decpro_emb True --share_output_emb True    --para_directions 'egy-msa,msa-egy' --n_para  -1   --lambda_xe_para '0:1,10000:0.1,30000:0'  --exp_id  test1

